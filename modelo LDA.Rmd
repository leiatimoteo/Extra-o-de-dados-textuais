---
title: "Análise textual com LDA (Latent Dirichlet Allocation)"
output: html_document
---

Este projeto utiliza o modelo de Latent Dirichlet Allocation (LDA) para análise de tópicos em um conjunto de textos. O objetivo é identificar os principais tópicos presentes nos documentos e visualizar os termos mais representativos de cada tópico.

```{r, warning=FALSE}
library(data.table)
library(tm)
library(tidyverse)
library(dplyr)
library(stopwords)
library(topicmodels)
library(broom)
library(writexl)
library(tidytext)
library(ggpubr)
library(readxl)  # Para ler o arquivo Excel
```

Visualizando os dados extraídos do site de notícias https://olhardigital.com.br

```{r}
dados <- read_excel("C:/Users/User/Downloads/dados_combinados.xlsx")
head(dados)
```

Preparação dos dados, incluindo a remoção de palavras irrelevantes (stopwords) e a criação de uma matriz de termos de documentos (DTM).

```{r, warning=FALSE}
corp <- VCorpus(VectorSource(dados$texto))
stopword_pt <- stopwords("pt")
corpus_base <- tm_map(corp, removeWords, stopword_pt)

dtm <- DocumentTermMatrix(corpus_base,
                          control = list(tolower = TRUE,
                                         removeNumbers = TRUE,
                                         removePunctuation = TRUE,
                                         stripWhitespace = TRUE,
                                         bounds = list(global = c(15, Inf))))

# Converter a DTM 
dtm.matrix <- as.matrix(dtm)
head(dtm.matrix,2)
```


### modelo LDA com 15 tópicos

```{r, warning=FALSE}
modelo_Ida <- LDA(dtm, k = 15, method = "Gibbs", control = list(seed = 1234))

### probabilidades dos tópicos
beta_topics <- tidy(modelo_Ida, matrix = "beta")
beta_topics
```


Os 10 principais termos por tópico:

```{r, warning=FALSE}
beta_top_terms <- beta_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)
beta_top_terms
```

```{r, warning=FALSE}
grupos <- beta_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +
  labs(x = "Probabilidade (Beta)", y = "Termos", title = "Termos por Tópicos") +
  theme_minimal()

print(grupos)
```


As distribuições dos tópicos para cada documento:

```{r, warning=FALSE}
documento_topico <- tidy(modelo_Ida, matrix = "gamma")
documento_topico

#distribuições de tópicos por documento
matriz_documento_topico <- documento_topico %>%
  pivot_wider(names_from = topic, values_from = gamma)

head(matriz_documento_topico)

```

Os tópicos identificados estão relacionados a áreas específicas, como economia, saúde, e tecnologia, e os termos mais frequentes dentro de cada tópico ajudam a entender as questões centrais discutidas.
O LDA demonstrou um bom desempenho ao identificar não apenas as palavras que costumam aparecer juntas, mas também ao capturar temas presentes nos textos.